{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4Y0BjJdQltS"
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "genai.configure(api_key=\"AIzaSyDKcxALky8LiROaxb0RGMw8TLLOcujMRMY\")\n"
      ],
      "metadata": {
        "id": "mMh0gh-3RgvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-pro\")"
      ],
      "metadata": {
        "id": "vKz0P25aRjmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt0():\n",
        "  prompt_parts=[f'''generate a passage/story of 500 words to test a child's comprehensive and understanding ability.Return the generated passage''',]\n",
        "  return prompt_parts"
      ],
      "metadata": {
        "id": "i0h3DngZSCC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt1(passage):\n",
        "  prompt_parts=[f'''\n",
        "  Given the following passage/story {passage}, generate comprehension mutiple choice questions to test a child's understanding. Provide feedback and explanations for each question.\n",
        "  Passage/Story:\n",
        "  [Insert the passage or story here.]\n",
        "  Instructions:\n",
        "  1. Generate multiple-choice only based on the content of the passage/story.\n",
        "  2. Ensure that the questions cover various aspects such as main ideas, details, inference, vocabulary, and author's purpose.\n",
        "  3. Provide feedback and explanations for each question to help the child learn from their mistakes.\n",
        "  4. Aim for a mix of easy, moderate, and challenging questions to cater to different levels of comprehension.\n",
        "\n",
        "  Example questions:\n",
        "  1. What is the main idea of the passage/story?\n",
        "   A) Option 1\n",
        "   B) Option 2\n",
        "   C) Option 3\n",
        "   D) Option 4\n",
        "\n",
        "   2. What does the word \"_____\" mean in the context of the passage/story?\n",
        "   A) Option 1\n",
        "   B) Option 2\n",
        "   C) Option 3\n",
        "   D) Option 4\n",
        "\n",
        "   3. Based on the passage/story, what can you infer about ____?\n",
        "   A) Option 1\n",
        "   B) Option 2\n",
        "   C) Option 3\n",
        "   D) Optilon 4\n",
        "   the ouput should a dictionary where each key is the question and its value must be python dictionary of the form {{options,answer,feedback}}\n",
        "    where options correspond to a comma-seperated list of 4 options(a,b,c,d) to choose from(for example: what as the name? a)lucas  b)maua c) peter d)Ian\n",
        "  and answer in the right option (either 0 or 1 or 2 or 3 representing the index of the right answer in the list) and feedback is the feedback.\n",
        "   i want the output to be a python code of the datatype dict.\n",
        "  ''' ,]\n",
        "  return prompt_parts\n"
      ],
      "metadata": {
        "id": "LzUHghCkRl8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "gfudF5YmTbWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt0=prompt0,prompt1=prompt1,model=model,to_markdown=to_markdown):\n",
        "  human_prompt1=prompt0()\n",
        "  response1 = model.generate_content(human_prompt1)\n",
        "  passage = response1.text\n",
        "  print(passage)\n",
        "  human_prompt2=prompt1(passage)\n",
        "  response2 = model.generate_content(human_prompt2)\n",
        "  return response2.text\n"
      ],
      "metadata": {
        "id": "5U7hYmeKUvKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=generate()"
      ],
      "metadata": {
        "id": "tC1O01dUVBq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "id": "yYqGssCOVGlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=a.find('{')\n",
        "extracted_string = a[i:-4]\n",
        "print(\"Extracted string:\", extracted_string)"
      ],
      "metadata": {
        "id": "lz5oISCXn2cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=eval(extracted_string)\n",
        "d"
      ],
      "metadata": {
        "id": "Ashw5obwoKjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(d)"
      ],
      "metadata": {
        "id": "H_O9ULaTpJiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s=0\n",
        "for i in d:\n",
        "  print(\"\\n\",i)\n",
        "  print(\"options: \",d[i]['options'])\n",
        "  a=int(input(\"enter answer: \"))\n",
        "  b=d[i]['answer']\n",
        "  print('correct answer: ',d[i]['answer'])\n",
        "  print(\"feedback: \",d[i]['feedback'])\n",
        "  if a==b:\n",
        "    s+=1\n",
        "print('\\nscore: ',s)"
      ],
      "metadata": {
        "id": "giDrTO7DpTTR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}